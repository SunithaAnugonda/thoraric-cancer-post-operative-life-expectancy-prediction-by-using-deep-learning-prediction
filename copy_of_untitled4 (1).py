# -*- coding: utf-8 -*-
"""Copy of Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pbWohq7NFW_5MzD8ByZD0CdUsYfoP76N
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.utils import shuffle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import precision_recall_curve

data = pd.read_csv("ThoraricSurgery.csv")

data.head()

data.columns

data.info()

# Identify duplicates based on all columns
data.duplicated().sum()

data.isna().sum()

print("\nSummary statistics:")
print(data.describe())

""" Basic information about the dataset"""

# Function for data augmentation on specific columns
def augment_data(input_data, target_columns, seed_value):
  np.random.seed(seed_value)  # Set seed for reproducibility
  augmented_data = input_data.copy()
  # Apply augmentation to specific columns
  for col in target_columns:
    if col in augmented_data.columns:
      # Random noise
      augmented_data[col] += np.random.normal(0, 0.1, size=len(input_data))
      # Random sampling
      augmented_data[col] = shuffle(augmented_data[col], random_state=seed_value)
      # Permutationn
      np.random.seed(seed_value)  # Set seed for reproducibility within the loop
      augmented_data[col] = np.random.permutation(augmented_data[col])
      # Randomization (shuffle rows)
      augmented_data = shuffle(augmented_data, random_state=seed_value)
      # Return the augmented data
      return augmented_data

# Set seed value for reproducibility
seed_value = 144

# Specify columns to augment
columns_to_augment = ['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17']

# Apply data augmentation to specific columns
augmented_data = augment_data(data, target_columns=columns_to_augment, seed_value=seed_value)

# Save or further use augmented_data
augmented_data.to_csv("AugmentedThoracicSurgery.csv", index=False)

augmented_data.head()

"""correlation of the map"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

# Read the augmented dataset
augmented_data = pd.read_csv("AugmentedThoracicSurgery.csv")

# Select the categorical columns
categorical_columns = ['DGN', 'PRE6', 'PRE7', 'PRE8', 'PRE9', 'PRE10', 'PRE11', 'PRE14', 'PRE17', 'PRE19', 'PRE25', 'PRE30', 'PRE32', 'Risk1Yr']

# Encode the categorical columns
encoded_data = augmented_data.copy()
for col in categorical_columns:
    if augmented_data[col].dtype == 'object':
        encoded_data[col] = LabelEncoder().fit_transform(augmented_data[col])

# Calculate the correlation matrix
correlation_matrix = encoded_data.corr()

# Plot the correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Read the dataset
data = pd.read_csv("ThoraricSurgery.csv")

# Define the numerical columns
numerical_columns = ['PRE4', 'PRE5', 'AGE']

# Calculate the correlation matrix for numerical columns
correlation_matrix_numerical = data[numerical_columns].corr()

# Print the correlation matrix for numerical columns
print("Correlation Matrix for Numerical Columns:")
print(correlation_matrix_numerical)

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Read the augmented dataset
augmented_data = pd.read_csv("AugmentedThoracicSurgery.csv")

# Select the categorical columns
categorical_columns = ['DGN', 'PRE6', 'PRE7', 'PRE8', 'PRE9', 'PRE10', 'PRE11', 'PRE14', 'PRE17', 'PRE19', 'PRE25', 'PRE30', 'PRE32', 'Risk1Yr']

# Calculate the correlation between PRE4 and each categorical column
for col in categorical_columns:
    if augmented_data[col].dtype == 'object':
        # Convert categorical column to numerical using LabelEncoder
        encoded_column = LabelEncoder().fit_transform(augmented_data[col])
        # Calculate the correlation
        correlation = np.corrcoef(encoded_column, augmented_data['PRE4'])[0, 1]
        print(f"Correlation between {col} and PRE4: {correlation:.4f}")

label_encoder = LabelEncoder()
augmented_data['DGN'] = label_encoder.fit_transform(data['DGN'])
augmented_data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
augmented_data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
augmented_data.replace({'F': 0, 'T': 1}, inplace=True)
augmented_data.head()

X = augmented_data[['PRE4','PRE5','PRE32','PRE30','PRE25','PRE19','PRE17','AGE']]
y = augmented_data['Risk1Yr'].values

print(X)
print(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)

X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

model = models.Sequential()
model.add(layers.LSTM(64, input_shape=(X_train.shape[1], 1)))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train.reshape(-1, 1), epochs=10, batch_size=128, validation_split=0.30)

y_pred = model.predict(X_test_reshaped)
threshold = 0.3  # You can adjust this threshold based on your needs

# Convert predicted probabilities to classes using the threshold
y_pred_classes = (y_pred > threshold).astype(int)



# Calculate metrics
accuracy = accuracy_score(y_test, y_pred_classes) * 100
conf_matrix = confusion_matrix(y_test, y_pred_classes)

tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)
roc_auc = roc_auc_score(y_test, y_pred)

# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")
print(f"ROC AUC: {roc_auc:.2f}")

# Plot ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred)
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Extract training history for accuracy
training_accuracy = history.history['accuracy']
validation_accuracy = history.history['val_accuracy']

# Visualize training and validation accuracy
plt.plot(training_accuracy, label='Training Accuracy')
plt.plot(validation_accuracy, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

""" Multi-layer Perceptron (MLP) for Binary Classification"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.optimizers import Adam
from keras.optimizers import SGD
from sklearn.utils import shuffle

# Load data
data = pd.read_csv("ThoraricSurgery.csv")

# Function for data augmentation on specific columns
def augment_data(input_data, target_columns, seed_value):
    np.random.seed(seed_value)  # Set seed for reproducibility
    augmented_data = input_data.copy()

    # Apply augmentation to specific columns
    for col in target_columns:
        if col in augmented_data.columns:
            # Check if the column is numeric
            if pd.api.types.is_numeric_dtype(augmented_data[col]):

                # Random noise for numeric columns
                augmented_data[col] += np.random.normal(0, 0.1, size=len(input_data))
            else:
                # For non-numeric columns, perform other types of augmentation
                augmented_data[col] = shuffle(augmented_data[col], random_state=seed_value)
                np.random.seed(seed_value)  # Set seed for reproducibility within the loop
                augmented_data[col] = np.random.permutation(augmented_data[col])
                # Feature engineering (you can add your own feature engineering here)
                augmented_data['NewFeature'] = augmented_data['PRE4'] * augmented_data['AGE']
                # Randomization (shuffle rows)
                augmented_data = shuffle(augmented_data, random_state=seed_value)

    # Return the augmented data
    return augmented_data

# Set seed value for reproducibility
seed_value = 144

# Specify columns to augment
columns_to_augment = ['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17']

# Apply data augmentation to specific columns
augmented_data = augment_data(data, target_columns=columns_to_augment, seed_value=seed_value)

# Save or further use augmented_data
augmented_data.to_csv("AugmentedThoracicSurgery.csv", index=False)

label_encoder = LabelEncoder()
augmented_data['DGN'] = label_encoder.fit_transform(data['DGN'])
augmented_data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
augmented_data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
augmented_data.replace({'F': 0, 'T': 1}, inplace=True)
X = augmented_data[['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17', 'AGE']]
y = augmented_data['Risk1Yr']

# Use LabelEncoder for binary classification
y = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)
X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build a simple Multilayer Perceptron (MLP) model using Keras
model = models.Sequential()

model.add(layers.Dense(64, input_shape=(X_train.shape[1],)))
model.add(layers.Activation('elu'))  # Exponential Linear Unit (ELU)

model.add(layers.Dense(32))
model.add(layers.PReLU())  # Parametric Rectified Linear Unit (PReLU)

model.add(layers.Dense(32))
model.add(layers.Activation('relu'))  # Rectified Linear Unit (ReLU)

model.add(layers.Dense(16))
model.add(layers.Activation('swish'))  # Swish Activation

model.add(layers.Dense(16))
model.add(layers.Activation('tanh'))  # Hyperbolic Tangent (tanh) Activation

model.add(layers.Dense(8))
model.add(layers.Activation('sigmoid'))  # Sigmoid Activation

# Fully connected layers (Added more layers)
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(64, activation='relu'))

# Updated the final layer for binary classification
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.3)








from sklearn.metrics import classification_report, confusion_matrix

# Make predictions
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.3).astype(int)  # Convert probabilities to binary predictions

# Compute confusion matrix
accuracy = accuracy_score(y_test, y_pred) * 100
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)


# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")




# Classification report
#print("\nClassification Report:")
#print(classification_report(y_test, y_pred))

"""Bidirectional LSTM Neural Network for Binary Classification on Thoracic Surgery Dataset"
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.optimizers import Adam
from sklearn.utils import shuffle

# Read the data
data = pd.read_csv("ThoraricSurgery.csv")

# Function for data augmentation on specific columns
def augment_data(input_data, target_columns, seed_value):
    np.random.seed(seed_value)
    augmented_data = input_data.copy()

    for col in target_columns:
        if col in augmented_data.columns:
            # Check if the column is numeric
            if pd.api.types.is_numeric_dtype(augmented_data[col]):
                # Random noise for numeric columns
                augmented_data[col] += np.random.normal(0, 0.1, size=len(input_data))
            else:
                # For non-numeric columns, perform other types of augmentation
                augmented_data[col] = shuffle(augmented_data[col], random_state=seed_value)
                np.random.seed(seed_value)  # Set seed for reproducibility within the loop
                augmented_data[col] = np.random.permutation(augmented_data[col])
                # Feature engineering (you can add your own feature engineering here)
                augmented_data['NewFeature'] = augmented_data['PRE4'] * augmented_data['AGE']
                # Randomization (shuffle rows)
                augmented_data = shuffle(augmented_data, random_state=seed_value)

    # Return the augmented data
    return augmented_data

# Set seed value for reproducibility
seed_value = 144

# Specify columns to augment
columns_to_augment = ['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17']

# Apply data augmentation to specific columns
augmented_data = augment_data(data, target_columns=columns_to_augment, seed_value=seed_value)

# Save or further use augmented_data
augmented_data.to_csv("AugmentedThoracicSurgery.csv", index=False)

label_encoder = LabelEncoder()
augmented_data['DGN'] = label_encoder.fit_transform(data['DGN'])
augmented_data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
augmented_data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
augmented_data.replace({'F': 0, 'T': 1}, inplace=True)
X = augmented_data[['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17', 'AGE']]
y = augmented_data['Risk1Yr']
y = np.expand_dims(y, axis=-1)  # Adjust the shape to (None, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)
X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

# Model Architecture with Bidirectional LSTMs and increased units
model = models.Sequential()
model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True), input_shape=(X_train.shape[1], 1)))
model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True)))
model.add(layers.Bidirectional(layers.LSTM(64)))
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation='sigmoid'))  # Change to 1 unit for binary classification

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Training
history = model.fit(X_train_reshaped, y_train, epochs=30, batch_size=64, validation_split=0.3, verbose=1)

# Evaluation
y_pred = model.predict(X_test_reshaped)
y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary classes
accuracy = accuracy_score(y_test, y_pred_classes) * 100
conf_matrix = confusion_matrix(y_test, y_pred_classes)
tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)


# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")

""""Enhanced InceptionV1 Model for Binary Classification on Thoracic Surgery Dataset"
"""

!pip install tensorflow keras
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow.keras import layers, models

# Load data
data = pd.read_csv("ThoraricSurgery.csv")

# Encode categorical columns
label_encoder = LabelEncoder()
data['DGN'] = label_encoder.fit_transform(data['DGN'])
data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
data.replace({'F': 0, 'T': 1}, inplace=True)

# Normalize numerical columns
scaler = StandardScaler()
numerical_columns = ['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17', 'AGE']
data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Prepare features and target
X = data[numerical_columns]
y = data['Risk1Yr']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)

# Reshape for 1D convolution
X_train_3D = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_3D = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

# Model architecture using modified InceptionV1 with more layers
def build_inception_model(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)

    x = layers.Conv1D(64, kernel_size=1, activation='relu', padding='same')(inputs)
    x = layers.MaxPooling1D(pool_size=2)(x)

    # Inception module 1
    x = inception_module(x, filters=(64, 128, 32, 32))

    # Inception module 2
    x = inception_module(x, filters=(128, 192, 96, 64))

    # Inception module 3 (Added more layers)
    x = inception_module(x, filters=(192, 256, 128, 64))

    # Global average pooling
    x = layers.GlobalAveragePooling1D()(x)

    # Fully connected layers (Added more layers)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dense(64, activation='relu')(x)

    outputs = layers.Dense(num_classes, activation='sigmoid')(x)

    model = models.Model(inputs, outputs)
    return model

def inception_module(x, filters):
    conv1x1 = layers.Conv1D(filters[0], kernel_size=1, activation='relu', padding='same')(x)
    conv3x3 = layers.Conv1D(filters[1], kernel_size=3, activation='relu', padding='same')(x)
    conv5x5 = layers.Conv1D(filters[2], kernel_size=5, activation='relu', padding='same')(x)

    conv1x1_2 = layers.Conv1D(filters[3], kernel_size=1, activation='relu', padding='same')(x)

    inception = layers.Concatenate(axis=-1)([conv1x1, conv3x3, conv5x5, conv1x1_2])
    return inception

# Build the modified InceptionV1 model with more layers
input_shape = (X_train_3D.shape[1], X_train_3D.shape[2])
num_classes = 1
model = build_inception_model(input_shape, num_classes)

# Compile the model with an adjusted learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train_3D, y_train, epochs=20, batch_size=20, validation_split=0.3)




from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
y_pred = model.predict(X_test_3D)
y_pred_binary = np.round(y_pred)
accuracy = accuracy_score(y_test, y_pred_binary) * 100
conf_matrix = confusion_matrix(y_test, y_pred_binary)
tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)


# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")


# Classification report
#print("\nClassification Report:")
#print(classification_report(y_test, y_pred_binary))

"""Modified ResNet Model with Enhanced Dense Layers for Binary Classification on Thoracic Surgery Dataset"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks

# Load data
data = pd.read_csv("ThoraricSurgery.csv")

# Encode categorical variables and replace binary values
label_encoder = LabelEncoder()
data['DGN'] = label_encoder.fit_transform(data['DGN'])
data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
data.replace({'F': 0, 'T': 1}, inplace=True)

# Prepare data
X = data[['PRE4','PRE5','PRE32','PRE30','PRE25','PRE19','PRE17','AGE']]
y = data['Risk1Yr']

# Normalize input features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)

# Reshape input for 1D convolution
X_train_3D = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_3D = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build ResNet model with modifications
def build_resnet(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)

    # Feature extraction block
    x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)
    x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)
    x = layers.MaxPooling1D(pool_size=2)(x)

    # Residual blocks
    for _ in range(3):
        residual = x
        x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)
        x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)
        x = layers.Add()([x, residual])
        x = layers.Activation('relu')(x)

    # Global average pooling
    x = layers.GlobalAveragePooling1D()(x)

    # Fully connected layers
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dense(64, activation='relu')(x)  # Additional dense layer
    outputs = layers.Dense(num_classes, activation='sigmoid')(x)

    model = models.Model(inputs, outputs)
    return model

input_shape = (X_train_3D.shape[1], X_train_3D.shape[2])
num_classes = 1
model = build_resnet(input_shape, num_classes)

# Compile model with Adam optimizer and learning rate scheduler
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Learning rate scheduler
lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)

# Train the model with the modified data
history = model.fit(X_train_3D, y_train, epochs=50, batch_size=50, validation_split=0.4, callbacks=[lr_scheduler])

# Evaluate the model
y_pred = model.predict(X_test_3D)
y_pred_binary = np.round(y_pred)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
y_pred = model.predict(X_test_3D)
y_pred_binary = np.round(y_pred)
accuracy = accuracy_score(y_test, y_pred_binary) * 100
conf_matrix = confusion_matrix(y_test, y_pred_binary)
tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)


# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")


# Classification report
#print("\nClassification Report:")
#print(classification_report(y_test, y_pred_binary))

"""DenseNet"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks

# Load data
data = pd.read_csv("ThoraricSurgery.csv")

# Encode categorical variables and replace binary values
label_encoder = LabelEncoder()
data['DGN'] = label_encoder.fit_transform(data['DGN'])
data['PRE6'] = label_encoder.fit_transform(data['PRE6'])
data['PRE14'] = label_encoder.fit_transform(data['PRE14'])
data.replace({'F': 0, 'T': 1}, inplace=True)

# Prepare data
X = data[['PRE4', 'PRE5', 'PRE32', 'PRE30', 'PRE25', 'PRE19', 'PRE17', 'AGE']]
y = data['Risk1Yr']

# Normalize input features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)

# Reshape input for 1D convolution
X_train_3D = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_3D = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Build DenseNet model with modifications
def build_densenet(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)

    # Initial convolutional layer
    x = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)

    # Dense blocks
    for _ in range(3):
        # Dense block
        x_concat = x
        for _ in range(4):
            x_branch = layers.Conv1D(32, kernel_size=1, activation='relu', padding='same')(x_concat)
            x_branch = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(x_branch)
            x_concat = layers.Concatenate(axis=-1)([x_concat, x_branch])

        # Transition layer
        x = layers.Conv1D(64, kernel_size=1, activation='relu', padding='same')(x_concat)
        x = layers.MaxPooling1D(pool_size=2)(x)

    # Global average pooling
    x = layers.GlobalAveragePooling1D()(x)

    # Fully connected layers
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dense(64, activation='relu')(x)  # Additional dense layer
    outputs = layers.Dense(num_classes, activation='sigmoid')(x)

    model = models.Model(inputs, outputs)
    return model

input_shape = (X_train_3D.shape[1], X_train_3D.shape[2])
num_classes = 1
model = build_densenet(input_shape, num_classes)

# Compile model with Adam optimizer and learning rate scheduler
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Learning rate scheduler
lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)

# Train the model with the modified data
history = model.fit(X_train_3D, y_train, epochs=20, batch_size=128, validation_split=0.3, callbacks=[lr_scheduler])

# Evaluate the model
y_pred = model.predict(X_test_3D)
y_pred_binary = np.round(y_pred)
accuracy = accuracy_score(y_test, y_pred_binary)
print(f"Accuracy: {accuracy}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
y_pred = model.predict(X_test_3D)
y_pred_binary = np.round(y_pred)
accuracy = accuracy_score(y_test, y_pred_binary) * 100
conf_matrix = confusion_matrix(y_test, y_pred_binary)
tn, fp, fn, tp = conf_matrix[1][1], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[0][0]

sensitivity = tp / (tp + fn)
specificity = accuracy - sensitivity

precision = tp / (tp + fp)
recall = sensitivity  # Recall is another name for sensitivity
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)


# Print metrics
print(f"Accuracy: {accuracy:.2f}%")
print(f"Specificity: {specificity:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")


# Classification report
#print("\nClassification Report:")
#print(classification_report(y_test, y_pred_binary))

import matplotlib.pyplot as plt

# Data
models = ['LSTM', 'BiLSTM', 'BiLSTM + Feedforward', 'MLP with Augmentation', 'InceptionV1', 'ResNet', 'DenseNet-like']
accuracies = [92.96, 91.55, 91.55, 91.55, 88.30, 88.30, 86.17]

# Create bar graph
plt.figure(figsize=(10, 6))
bars = plt.bar(models, accuracies, color='skyblue')

# Add percentages on top of each bar
for bar, accuracy in zip(bars, accuracies):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.5, f'{accuracy:.2f}%', ha='center', va='bottom')

# Add labels and title
plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy of Different Models')
plt.xticks(rotation=45, ha='right')

# Show plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Define performance measures for each algorithm
performance_measures = {
    'LSTM': {'Accuracy': 92.96, 'Specificity': 92.03, 'Recall': 0.93, 'Precision': 1.00, 'F1-Score': 0.96},
    'Multi-layer Perceptron (MLP)': {'Accuracy': 91.55, 'Specificity': 90.63, 'Recall': 0.92, 'Precision': 1.00, 'F1-Score': 0.96},
    'Bidirectional LSTM': {'Accuracy': 91.55, 'Specificity': 90.63, 'Recall': 0.92, 'Precision': 1.00, 'F1-Score': 0.96},
    'InceptionV1': {'Accuracy': 88.30, 'Specificity': 87.41, 'Recall': 0.88, 'Precision': 1.00, 'F1-Score': 0.94},
    'ResNet Model': {'Accuracy': 88.30, 'Specificity': 87.41, 'Recall': 0.88, 'Precision': 1.00, 'F1-Score': 0.94},
    'DenseNet': {'Accuracy': 88.30, 'Specificity': 87.41, 'Recall': 0.88, 'Precision': 1.00, 'F1-Score': 0.94}
}

# Plotting
plt.figure(figsize=(10, 6))

for algorithm, measures in performance_measures.items():
    x = list(measures.keys())
    y = list(measures.values())
    plt.plot(x, y, marker='o', label=algorithm)

plt.xlabel('Performance Measures')
plt.ylabel('Percentage')
plt.title('Performance Measures of Different Algorithms')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.show()



import matplotlib.pyplot as plt

# Define algorithms and their performance measures
algorithms = ['LSTM', 'MLP', 'BiLSTM', 'InceptionV1', 'ResNet', 'DenseNet-like']
accuracy = [92.96, 91.55, 91.55, 88.30, 88.30, 88.30]
specificity = [92.03, 90.63, 90.63, 87.41, 87.41, 87.41]
recall = [93, 92, 92, 88, 88, 88]
precision = [100, 100, 100, 100, 100, 100]
f1_score = [96, 96, 96, 94, 94, 94]

# Set up the figure and axes
plt.figure(figsize=(10, 6))
index = range(len(algorithms))
bar_width = 0.2

# Plot bars for each performance measure
plt.bar(index, accuracy, bar_width, label='Accuracy')
plt.bar([i + bar_width for i in index], precision, bar_width, label='Precision')
plt.bar([i + 2 * bar_width for i in index], recall, bar_width, label='Recall')
plt.bar([i + 3 * bar_width for i in index], f1_score, bar_width, label='F1 Score')

# Add labels and title
plt.xlabel('Algorithms')
plt.ylabel('Performance Measures')
plt.title('Performance Measure Comparison for Different Algorithms')
plt.xticks([i + 1.5 * bar_width for i in index], algorithms)
plt.legend()

# Save plot with DPI set to 1200
plt.tight_layout()
plt.savefig('performance_comparison.png', dpi=1200)
plt.show()